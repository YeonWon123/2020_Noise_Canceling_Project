{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_Test_final",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOj8HVOD62Wr"
      },
      "source": [
        "# Code By adityatb at https://github.com/adityatb/noise-reduction-using-rnn\n",
        "# LSTM method test.\n",
        "# Maintain by ShYy, 2018.\n",
        "import tensorflow as tf\n",
        "import scipy\n",
        "import scipy.signal as signal\n",
        "import numpy as np\n",
        "import os, random, sys\n",
        "import scipy.io.wavfile as wav\n",
        "import math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wSKIIy8CgJ3",
        "outputId": "b19212a2-5515-40c2-eec4-18d07c7e02c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x94grFaxCgQ2",
        "outputId": "58657665-a638-4a3b-a731-6615baf4de2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/gdrive/My Drive/Data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjUjTNQRCgwx",
        "outputId": "29582cc1-8f5f-4481-ac06-010736f20f4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/Data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNk2uTY1n-cX"
      },
      "source": [
        "## 함수정의부"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR3KLZaV62wY"
      },
      "source": [
        "#filename을 입력받아 앞에서부터 len(filename)-11 까지만 남긴 뒤 _voice 추가\n",
        "def formatFilename(filename):\n",
        "    return filename[:len(filename) - 11] + \"_voice.wav\"\n",
        "\n",
        "# Strip away the _xnoise.wav part of the filename, and append _voice.wav to obtain clean voice counterpart\n",
        "\n",
        "def create_final_sequence(sequence, max_length):\n",
        "    a, b = sequence.shape\n",
        "    extra_len = max_length - b\n",
        "    null_mat = np.zeros((len(sequence), extra_len), dtype=np.float32)\n",
        "    sequence = np.concatenate((sequence, null_mat), axis=1)\n",
        "    return sequence\n",
        "\n",
        "def sequentialized_spectrum(batch):   #여기서 batch는 데이터가 들어있는 repository를 의미한다.\n",
        "    # Get maximum length of batch\n",
        "    t = []\n",
        "    t_vec = []\n",
        "    Sxx_Vec = []\n",
        "    for each in batch:\n",
        "        _, t, Sxx_Vec_Temp = signal.stft(each, fs=16000, nperseg=stft_size, return_onesided = False) #signal module의 stft사용후 frequency, time, Zxx가 생성됨\n",
        "        t_vec.append(t)\n",
        "        Sxx_Vec.append(Sxx_Vec_Temp)\n",
        "    \n",
        "    maximum_length = findMaxlen(t_vec)\n",
        "    max_run_total = int(math.ceil(float(maximum_length) / sequence_length))  #trainig data중 최대의 길이를 100으로 나눈 값\n",
        "\n",
        "    #모든길이를 400으로 고정\n",
        "    #true_time은 어떻게 해줘야하나... 각 시간 정보만 넣으면 되므로? 1로 설정(일단)\n",
        "    final_data = np.zeros([len(file_repository), stft_size, max_run_total*sequence_length])\n",
        "    true_time = np.zeros([len(file_repository), 1])\n",
        "\n",
        "    # Read in a file and compute spectrum\n",
        "    # for batch_idx, each_set in enumerate(batch):\n",
        "    for batch_idx, Sxx in enumerate(Sxx_Vec):\n",
        "\n",
        "        # Magnitude and Phase Spectra\n",
        "        Mag = Sxx.real\n",
        "        t = t_vec[batch_idx]  #왜 굳이? 옮기는건지는 모르겠음 아무튼 t와 t_vec은 동일\n",
        "        # Phase = Sxx.imag\n",
        "\n",
        "        # Break up the spectrum in sequence_length sized data\n",
        "        #해당 인덱스에 해당하는 Audio의 길이 = run_full_step 즉 total time step 이라고 생각하면댐\n",
        "        run_full_steps = float(len(t)) / sequence_length #311/100 = 3.11 -> 4 \n",
        "        run_total = int(math.ceil(run_full_steps))  #ceil 올림함수\n",
        "        run_floor = int(math.floor(run_full_steps))\n",
        "\n",
        "        #final_data[batch_idx,:,:] = np.copy(create_final_sequence(Mag, run_total*sequence_length))\n",
        "        final_data[batch_idx,:,:] = np.copy(create_final_sequence(Mag, 400))\n",
        "        true_time[batch_idx] = 400\n",
        "\n",
        "    final_data = np.transpose(final_data, (0, 2, 1))\n",
        "\n",
        "    return final_data, true_time, maximum_length\n",
        "\n",
        "\n",
        "def findMaxlen(data_vec):\n",
        "    max_ = 0\n",
        "    for each in data_vec:\n",
        "        if len(each) > max_:\n",
        "            max_ = len(each)\n",
        "    return max_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRnia26LoBh6"
      },
      "source": [
        "## modeling에 필요한 변수들 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WYR-acE62y_"
      },
      "source": [
        "########################################## input으로 넣을 Data 경로설정 ########################################################\n",
        "# input, output path 입력\n",
        "input_data = os.getcwd() + \"/Testing/NoiseAdded3/\"\n",
        "modelOutput = os.getcwd() + \"/Testing/ModelOutput6\"\n",
        "\n",
        "# NormConstant\n",
        "norm_factor = (1 / 32768.0)\n",
        "\n",
        "# Spectrogram Parameters\n",
        "stft_size = 1024\n",
        "\n",
        "# RNN Specs\n",
        "sequence_length = 100\n",
        "batch_size = 100\n",
        "\n",
        "# Tensorflow vars + Graph and LSTM Params --------------------------------------------------------------- tf 1.0 model 생성 시작 -----------------------------------------------------\n",
        "# Temp_data_variables\n",
        "no_of_files = 0\n",
        "temp_list = []\n",
        "final_data = []\n",
        "sequence_length_id = 0\n",
        "\n",
        "# Repositories\n",
        "file_repository = []\n",
        "\n",
        "# Selected vectors\n",
        "files_vec = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXE0idgvj-id"
      },
      "source": [
        "\n",
        "# test할 Data 들을 읽어와서 list에 저장 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCbDf8qfj3C3"
      },
      "source": [
        "# ------------------- Read all data to memory creating a repository of mixture and clean files --------------------- #\n",
        "#필요한 것, input 값들(noiseadded, humanvoice)\n",
        "os.chdir(input_data)\n",
        "# for file_iter in range(input_data):\n",
        "\n",
        "# Buffer training data to memory for faster execution:\n",
        "for root, _, files in os.walk(input_data):\n",
        "    files = sorted(files)\n",
        "    no_of_files = len(files)\n",
        "    \n",
        "    #files는 NoiseAdded data들을 의미하며 배치사이즈가 training data size보다 크면 말이 안되니까 여기서 에러처리\n",
        "    if batch_size > no_of_files:\n",
        "        sys.exit(\"Error: batch_size cannot be more than number of files in the training directory\")\n",
        "\n",
        "    #files를 읽어와 data와 samplingrate를 각각 리스트에 저장\n",
        "    for f in files:\n",
        "        if f.endswith(\".wav\"):\n",
        "            temp_list.append(f)\n",
        "            srate, data = wav.read(os.path.join(root, f))\n",
        "            file_repository.append(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAMIeEEfkK85"
      },
      "source": [
        "## sequentialized_spectrum 함수를 이용 푸리에 트랜스폼 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwgiS8H9ihFC"
      },
      "source": [
        "    #모든 배열의 원소에 norm_factor를 곱한다. sequentialized_spectrum함수를 \n",
        "    for file_iter in range(len(file_repository)):\n",
        "        i = random.randint(0, len(file_repository) - 1)\n",
        "        files_vec.append(file_repository[i] * norm_factor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXCti__ki9PR"
      },
      "source": [
        "    #stft_bach, clean_voice_batch를 생성\n",
        "    stft_batch, sequence_length_id, maximum_length = sequentialized_spectrum(files_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1gP-_lHldjR"
      },
      "source": [
        "## 트레이닝셋과 테스트셋 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh_NlubDzGY5"
      },
      "source": [
        "X_test = stft_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HEqWh8X6ZOs",
        "outputId": "17c731e0-0280-431b-d9ee-5ce277b71d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 400, 1024)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SpceIZumP5U"
      },
      "source": [
        "# 모델형성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-GsRDPrg-zU"
      },
      "source": [
        "#from keras.layers import LSTM \n",
        "#from keras.models import Sequential \n",
        "#from keras.layers import Dense\n",
        "#from keras.layers import Input, Dense, LSTM, TimeDistributed\n",
        "#import keras.backend as K\n",
        "#from keras.callbacks import EarlyStopping\n",
        "#from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9dxercTmp2v",
        "outputId": "dc1fc02b-2734-44a1-a2ec-940a245a35a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "#K.clear_session()\n",
        "model = load_model('/content/gdrive/My Drive/Data/Testing/model4/Epoch_076_Val_0.000.hdf5')\n",
        "model.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 400, 512)          3147776   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 400, 1024)         525312    \n",
            "=================================================================\n",
            "Total params: 3,673,088\n",
            "Trainable params: 3,673,088\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YED2PVZjk0on"
      },
      "source": [
        "Keras로 바꾼 부분은 여기까지\n",
        "\n",
        "model.predict로 최종 결과물 까지 확인해보고 싶으나\n",
        "역변환이 제대로 되지않는것을 확인해 아직 구현하지 않음\n",
        "추후 수정해야할 부분"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk_WJKu1D8vm"
      },
      "source": [
        "# Model을 적용시켜보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psz0WLXaca4v"
      },
      "source": [
        "modeloutput = model.predict(X_test)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9paPcanEEjGi",
        "outputId": "f6906c79-f03a-4504-fe7f-a3cccec83db3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "modeloutput.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 400, 1024)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tozBJizLEBSx",
        "outputId": "a0850035-9077-4905-9952-e3cfff066f81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Start Processing\n",
        "size = 3 #출력할 output file 수 지정\n",
        "for idx in range(size):\n",
        "\n",
        "    outputData = np.zeros([stft_size, sequence_length*4])           #np array 형식 지정\n",
        "\n",
        "    rnn_outputs_value = modeloutput[idx]\n",
        "    rnn_outputs_value = np.transpose(rnn_outputs_value, [1,0])      #역변환을 위해 위치 변경\n",
        "    outputData = rnn_outputs_value\n",
        "\n",
        "    # Compute ISTFT\n",
        "    _, outputData_ISTFT = signal.istft(outputData, fs=16000, nperseg=stft_size, input_onesided = False)       #inverse short term fourier transform\n",
        "\n",
        "    outputData_ISTFT = (outputData_ISTFT / norm_factor).real      #real 부분 추출\n",
        "    outputData_ISTFT = outputData_ISTFT.astype(np.int16)          #int 로 타입 변경\n",
        "\n",
        "    wav.write(modelOutput +'/file_outputs'+ str(idx) +\".wav\", 16000 , outputData_ISTFT)\n",
        "    print(\"output file Index: \" + str(idx))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index: 3\n",
            "Index: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF5KWJudSWII"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}