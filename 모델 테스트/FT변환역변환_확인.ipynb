{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FT변환역변환_확인.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNkWQ9S/LCRti9R8cDXqJit"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"YhGWu6pKtWkt","executionInfo":{"status":"ok","timestamp":1603009901842,"user_tz":-540,"elapsed":5031,"user":{"displayName":"이명신","photoUrl":"","userId":"07889795458184672383"}}},"source":["import tensorflow as tf\n","import scipy\n","import scipy.signal as signal\n","import numpy as np\n","import os, random, sys\n","import scipy.io.wavfile as wav\n","import math\n","import pandas as pd"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"7vjPjAzDtdKE","executionInfo":{"status":"ok","timestamp":1603009901842,"user_tz":-540,"elapsed":5023,"user":{"displayName":"이명신","photoUrl":"","userId":"07889795458184672383"}},"outputId":"03bbe478-5c93-4312-abc6-cac431204230","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KqZ-_CuzuXaW","executionInfo":{"status":"ok","timestamp":1603009901843,"user_tz":-540,"elapsed":5015,"user":{"displayName":"이명신","photoUrl":"","userId":"07889795458184672383"}},"outputId":"fa8b128f-6341-498a-9e2f-f3daaf4114f6","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd '/content/gdrive/My Drive/Data'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1KLxGMCUtu0Q","executionInfo":{"status":"ok","timestamp":1603009901843,"user_tz":-540,"elapsed":5009,"user":{"displayName":"이명신","photoUrl":"","userId":"07889795458184672383"}}},"source":["#filename을 입력받아 앞에서부터 len(filename)-11 까지만 남긴 뒤 _voice 추가\n","def formatFilename(filename):\n","    return filename[:len(filename) - 11] + \"_voice.wav\"\n","\n","\n","# Strip away the _xnoise.wav part of the filename, and append _voice.wav to obtain clean voice counterpart\n","\n","def create_final_sequence(sequence, max_length):\n","    a, b = sequence.shape\n","    extra_len = max_length - b\n","    null_mat = np.zeros((len(sequence), extra_len), dtype=np.float32)\n","    sequence = np.concatenate((sequence, null_mat), axis=1)\n","    return sequence\n","\n","\n","def sequentialized_spectrum(batch):\n","    # Get maximum length of batch\n","    t = []\n","    t_vec = []\n","    Sxx_Vec = []\n","    for each in batch:\n","        _, t, Sxx_Vec_Temp = signal.stft(each, fs=rate_repository[0], nperseg=stft_size, return_onesided = False) #frequency, time, Zxx\n","        t_vec.append(t)\n","        Sxx_Vec.append(Sxx_Vec_Temp)\n","    maximum_length = findMaxlen(t_vec)\n","\n","    max_run_total = int(math.ceil(float(maximum_length) / sequence_length))\n","    final_data = np.zeros([len(batch), max_run_total, stft_size, sequence_length])\n","    true_time = np.zeros([len(batch), max_run_total])\n","\n","    # Read in a file and compute spectrum\n","    # for batch_idx, each_set in enumerate(batch):\n","    for batch_idx, Sxx in enumerate(Sxx_Vec):\n","        # f, t, Sxx = signal.stft(each_set, fs=rate_repository[0], nperseg=stft_size, return_onesided = False)\n","\n","        # Magnitude and Phase Spectra\n","        Mag = Sxx.real\n","        t = t_vec[batch_idx]\n","        # Phase = Sxx.imag\n","\n","        # Break up the spectrum in sequence_length sized data\n","        run_full_steps = float(len(t)) / sequence_length\n","        run_total = int(math.ceil(run_full_steps))\n","\n","        # Run a loop long enough to break up all the data in the file into chunks of sequence_size\n","        for step in range(run_total):\n","\n","            begin_point = step * sequence_length\n","            end_point = begin_point + sequence_length\n","\n","            m, n = Mag[:, begin_point:end_point].shape\n","\n","            # Store each chunk sequentially in a new array, accounting for zero padding when close to the end of the file\n","            if n == sequence_length:\n","                final_data[batch_idx, step, :, :] = np.copy(Mag[:, begin_point:end_point])\n","                true_time[batch_idx, step] = n\n","            else:\n","                final_data[batch_idx, step, :, :] = np.copy(create_final_sequence(Mag[:, begin_point:end_point], sequence_length))\n","                true_time[batch_idx, step] = n\n","\n","    final_data = np.transpose(final_data, (0, 1, 3, 2))\n","\n","    return final_data, true_time, maximum_length\n","\n","\n","def findMaxlen(data_vec):\n","    max_ = 0\n","    for each in data_vec:\n","        if len(each) > max_:\n","            max_ = len(each)\n","    return max_"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ly9XlRNat3iP","executionInfo":{"status":"ok","timestamp":1603009901844,"user_tz":-540,"elapsed":5005,"user":{"displayName":"이명신","photoUrl":"","userId":"07889795458184672383"}}},"source":["# ----------------- Begin Vars --------------------- #\n","\n","# Training data directories\n","traindata = os.getcwd() + \"/Training/NoiseAdded/\"\n","voicedata = os.getcwd() + \"/Training/HumanVoices/\"\n","checkpoints = os.getcwd() + \"/TF_Checkpoints/\"\n","\n","# NormConstant\n","norm_factor = (1 / 32768.0)\n","\n","# Spectrogram Parameters\n","stft_size = 1024\n","\n","# RNN Specs\n","sequence_length = 100\n","batch_size = 1200\n","learning_rate = 0.001\n","epochs = 250\n","# number_of_layers = 3\n","\n","# Temp_data_variables\n","no_of_files = 0\n","temp_list = []\n","final_data = []\n","sequence_length_id = 0\n","\n","# Repositories\n","file_repository = []\n","rate_repository = []\n","clean_repository = []\n","\n","# Selected vectors\n","files_vec = []\n","clean_files_fin_vec = []\n","clean_files_vec = []"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6IK6gVOotbT5"},"source":["# 원본데이터에 대해 정상적으로 동작하는지 확인"]},{"cell_type":"code","metadata":{"id":"xYydE7xWtkoO","executionInfo":{"status":"ok","timestamp":1603009901844,"user_tz":-540,"elapsed":5000,"user":{"displayName":"이명신","photoUrl":"","userId":"07889795458184672383"}}},"source":["os.chdir(traindata)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"NX9E93vFt7vE","executionInfo":{"status":"ok","timestamp":1603009912288,"user_tz":-540,"elapsed":15439,"user":{"displayName":"이명신","photoUrl":"","userId":"07889795458184672383"}}},"source":["# Buffer training data to memory for faster execution:\n","for root, _, files in os.walk(traindata):\n","    files = sorted(files)\n","    no_of_files = len(files)\n","    \n","\n","    #files는 NoiseAdded data들을 의미하며 배치사이즈가 training data size보다 크면 말이 안되니까 여기서 에러처리\n","    if batch_size > no_of_files:\n","        sys.exit(\"Error: batch_size cannot be more than number of files in the training directory\")\n","\n","    #files를 읽어와 data와 samplingrate를 각각 리스트에 저장\n","    for f in files:\n","        if f.endswith(\".wav\"):\n","            temp_list.append(f)\n","            srate, data = wav.read(os.path.join(root, f))\n","            file_repository.append(data)\n","            rate_repository.append(srate)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cbSeUOknup5W"},"source":["data에 대한 file,rate 배열 생성"]},{"cell_type":"code","metadata":{"id":"a53Gr_H2ukVO","executionInfo":{"status":"ok","timestamp":1603009917156,"user_tz":-540,"elapsed":20299,"user":{"displayName":"이명신","photoUrl":"","userId":"07889795458184672383"}}},"source":["clean_files_vec = list(map(formatFilename, temp_list))\n","\n","#clean한 목소리 데이터들을 clean_repasitory에 저장\n","for root, _, files in os.walk(voicedata):\n","    files = sorted(files)\n","    for each in files:\n","        if each.endswith(\".wav\"):\n","            for name in clean_files_vec:\n","                if each == name:\n","                    srate2, data2 = wav.read(os.path.join(root, name))\n","                    clean_repository.append(data2)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gocmn--RuvL4"},"source":["humanvoice 배열 생성"]},{"cell_type":"code","metadata":{"id":"uWwJKIwWu0p6","executionInfo":{"status":"ok","timestamp":1603009918617,"user_tz":-540,"elapsed":21755,"user":{"displayName":"이명신","photoUrl":"","userId":"07889795458184672383"}}},"source":["    #모든 배열의 원소에 norm_factor를 곱한다. sequentialized_spectrum함수를 \n","    for file_iter in range(len(file_repository)):\n","        i = random.randint(0, len(file_repository) - 1)   #랜덤으로 data를 섞기위함\n","        files_vec.append(file_repository[i] * norm_factor)    #data에 norm 상수를 곱해 저장.\n","        clean_files_fin_vec.append(clean_repository[i] * norm_factor)   #clean_file에 norm 상수를 곱해 저장."],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A4Npwxequ9e7"},"source":["norm 상수를 곱한뒤 저장"]},{"cell_type":"code","metadata":{"id":"9Wgo38D-u_NG","executionInfo":{"status":"ok","timestamp":1603009943603,"user_tz":-540,"elapsed":15191,"user":{"displayName":"이명신","photoUrl":"","userId":"07889795458184672383"}}},"source":["    #stft_bach, clean_voice_batch를 생성\n","    stft_batch, sequence_length_id, maximum_length = sequentialized_spectrum(files_vec)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"vfM10Apg6sFc","executionInfo":{"status":"ok","timestamp":1603011271019,"user_tz":-540,"elapsed":1309,"user":{"displayName":"이명신","photoUrl":"","userId":"07889795458184672383"}},"outputId":"4e1b26be-29d3-4801-f2e9-d9b291e1ce43","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["stft_batch.shape"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2000, 4, 100, 1024)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"KgpG32DevsEq"},"source":["STFT 적용, stft_batch, sequence_lengh_id, maxium_length 생성\n","\n","stft_batch : \n","sequence_lengh_id : \n","maxium_length : repository에있던 data중 최대길이"]},{"cell_type":"markdown","metadata":{"id":"F3E7v4sZ13lq"},"source":["# 역 변환 시작"]},{"cell_type":"code","metadata":{"id":"peOBIjfX13AS","executionInfo":{"status":"error","timestamp":1603028482777,"user_tz":-540,"elapsed":955,"user":{"displayName":"이명신","photoUrl":"","userId":"07889795458184672383"}},"outputId":"7f14bebf-61a6-43e4-8ca1-2ef5ab652e0c","colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["\n","testFileNum = len(files)\n","\n","# Start Processing\n","for idx in range(testFileNum):\n","    nowNAFile = []\n","    nowNAFile.append(testNADataRepository[idx]) #testNADataRepository는 norm이 곱해진 stft전 data\n","\n","    # Get NA stft repository.\n","    nowNAData_STFT, sequenceLengthID, maxLength = sequentialized_spectrum(nowNAFile)\n","\n","    # Get Time Steps.\n","    maxTimeSteps = len(nowNAData_STFT[0])\n","\n","    # Define outputData List to contain rnn_outputs_value.\n","    outputData = np.zeros([1,  maxTimeSteps, stft_size, sequence_length])           # Transpose, [0, 1, 3, 2]\n","\n","    for timeStep in range(maxTimeSteps):\n","        #stft_batch[timeStep]가 이곳에 들어오면 됨!\n","        stft_batch[]\n","        rnn_outputs_value = np.transpose(rnn_outputs_value, [0, 2, 1])\n","        outputData[0][timeStep] = rnn_outputs_value\n","\n","    # Define outputData_STFT, link outputData List by timeStep in 1 dimension.-----------------------------------------------------------------------------\n","    outputData_STFT = np.zeros([stft_size, maxLength])\n","    beginTime = 0\n","    endTime = 0\n","    \n","    for timeStep in range(maxTimeSteps):\n","        if(timeStep < maxTimeSteps - 1):\n","            endTime = beginTime + sequence_length\n","            outputData_STFT[:, beginTime : endTime] = outputData[0, timeStep, :, :]\n","        else:\n","            endTime = beginTime + int(sequenceLengthID[0, timeStep])\n","            outputData_STFT[:, beginTime : endTime] = outputData[0, timeStep, :, 0 : (endTime - beginTime)]\n","\n","        beginTime = beginTime + sequence_length\n","\n","    # Compute ISTFT\n","    _, outputData_ISTFT = signal.istft(outputData_STFT, fs=testNARateRepository[0], nperseg=stft_size, input_onesided = False)\n","\n","    outputData_ISTFT = (outputData_ISTFT / norm_factor).real\n","    outputData_ISTFT = outputData_ISTFT.astype(np.int16)\n","\n","    #wav.write(modelOutput + outputFileList[idx], testNARateRepository[idx], outputData_ISTFT)\n","    print(\"Index: \" + str(idx))\n","    print(\"\\tOutput File: \" + str(outputFileList[idx]))"],"execution_count":16,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-10f1a271d66b>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    stft_batch[]\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"uBan6G488XbR"},"source":[""],"execution_count":null,"outputs":[]}]}