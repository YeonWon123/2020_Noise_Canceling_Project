{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Keras에서 LSTM(Long Short Term Memory) 네트워크에 대한 입력 데이터를 재구성 하는 방법.ipynb","provenance":[],"authorship_tag":"ABX9TyM4o+aSz8185T2i2JfQjmqE"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"PXNn1DdMDXYW"},"source":["def sequentialized_spectrum(batch):   #여기서 batch는 데이터가 들어있는 repository를 의미한다.\n","    # Get maximum length of batch\n","    t = []\n","    t_vec = []\n","    Sxx_Vec = []\n","    for each in batch:\n","        _, t, Sxx_Vec_Temp = signal.stft(each, fs=rate_repository[0], nperseg=stft_size, return_onesided = False) #signal module의 stft사용후 frequency, time, Zxx가 생성됨\n","        t_vec.append(t)\n","        Sxx_Vec.append(Sxx_Vec_Temp)\n","    maximum_length = findMaxlen(t_vec)\n","    #_ 는 Adam\n","    #t 는     \n","    #Sxx_Vec 은\n","\n","    #sequence length는 100으로 처음부터 할당되어 있다.\n","    #stft을 하는데 maixum length가 왜 나오는거지?\n","    #다 같은 간격으로 나뉘어서 ft되는거 아닌가?\n","    #여기서 t 가 뭘 의미하는건지 알아야 할듯\n","    #final_data와 true_time에 전체 데이터를 담기 위해 np.zeros로 초기화\n","\n","    max_run_total = int(math.ceil(float(maximum_length) / sequence_length))\n","    final_data = np.zeros([len(batch), max_run_total, stft_size, sequence_length])\n","    true_time = np.zeros([len(batch), max_run_total])\n","\n","    # Read in a file and compute spectrum\n","    # for batch_idx, each_set in enumerate(batch):\n","    for batch_idx, Sxx in enumerate(Sxx_Vec):\n","        #batch_idx는 인덱스, Sxx는 실제 값을 가지고 있음\n","        # f, t, Sxx = signal.stft(each_set, fs=rate_repository[0], nperseg=stft_size, return_onesided = False)\n","\n","        # Magnitude and Phase Spectra\n","        Mag = Sxx.real  #실수부 저장\n","        t = t_vec[batch_idx]  #t_값 변수에 저장\n","        # Phase = Sxx.imag\n","\n","        # Break up the spectrum in sequence_length sized data\n","        run_full_steps = float(len(t)) / sequence_length\n","        run_total = int(math.ceil(run_full_steps))\n","\n","        # Run a loop long enough to break up all the data in the file into chunks of sequence_size\n","        for step in range(run_total):\n","\n","            begin_point = step * sequence_length\n","            end_point = begin_point + sequence_length\n","\n","            m, n = Mag[:, begin_point:end_point].shape\n","\n","            # Store each chunk sequentially in a new array, accounting for zero padding when close to the end of the file\n","            if n == sequence_length:\n","                final_data[batch_idx, step, :, :] = np.copy(Mag[:, begin_point:end_point])\n","                true_time[batch_idx, step] = n\n","            else:\n","                final_data[batch_idx, step, :, :] = np.copy(create_final_sequence(Mag[:, begin_point:end_point], sequence_length))\n","                true_time[batch_idx, step] = n\n","\n","    final_data = np.transpose(final_data, (0, 1, 3, 2))\n","\n","    return final_data, true_time, maximum_length"],"execution_count":null,"outputs":[]}]}